{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d","showTitle":false,"title":""}},"source":["## Load CSV into Table\n","\n","This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n","\n","This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8ad4aa7f-7fd1-4059-9270-f8dc4628e615","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Files in SBPI Directory:\n","\n","CATEGORY.csv\n","CATEGORY_CH.csv\n","CATEGORY_US.csv\n","CURRENCY_MARKET.csv\n","CURRENCY_MARKET_CH.csv\n","CURRENCY_MARKET_US.csv\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Files in SBPI Directory:\n\nCATEGORY.csv\nCATEGORY_CH.csv\nCATEGORY_US.csv\nCURRENCY_MARKET.csv\nCURRENCY_MARKET_CH.csv\nCURRENCY_MARKET_US.csv\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["%sh \n","echo 'Files in  Directory:'\n","echo\n","ls /enter_path_here/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"764e418c-e782-47f4-8c86-b1e360cb81b9","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">file names:  [&#39;CATEGORY.csv&#39;, &#39;CATEGORY.html&#39;, &#39;CATEGORY_CH.csv&#39;, &#39;CATEGORY_US.csv&#39;, &#39;CURRENCY_MARKET.csv&#39;, &#39;CURRENCY_MARKET_CH.csv&#39;, &#39;CURRENCY_MARKET_US.csv&#39;, &#39;SC_STD_COUPON.html&#39;, &#39;SC_STD_NEW_ISSUE.html&#39;]\n","file paths:  [&#39;/SBPI/in_files/CATEGORY.csv&#39;, &#39;/SBPI/in_files/CATEGORY.html&#39;, &#39;/SBPI/in_files/CATEGORY_CH.csv&#39;, &#39;/SBPI/in_files/CATEGORY_US.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET_CH.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET_US.csv&#39;, &#39;/SBPI/in_files/SC_STD_COUPON.html&#39;, &#39;/SBPI/in_files/SC_STD_NEW_ISSUE.html&#39;]\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">file names:  [&#39;CATEGORY.csv&#39;, &#39;CATEGORY.html&#39;, &#39;CATEGORY_CH.csv&#39;, &#39;CATEGORY_US.csv&#39;, &#39;CURRENCY_MARKET.csv&#39;, &#39;CURRENCY_MARKET_CH.csv&#39;, &#39;CURRENCY_MARKET_US.csv&#39;, &#39;SC_STD_COUPON.html&#39;, &#39;SC_STD_NEW_ISSUE.html&#39;]\nfile paths:  [&#39;/SBPI/in_files/CATEGORY.csv&#39;, &#39;/SBPI/in_files/CATEGORY.html&#39;, &#39;/SBPI/in_files/CATEGORY_CH.csv&#39;, &#39;/SBPI/in_files/CATEGORY_US.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET_CH.csv&#39;, &#39;/SBPI/in_files/CURRENCY_MARKET_US.csv&#39;, &#39;/SBPI/in_files/SC_STD_COUPON.html&#39;, &#39;/SBPI/in_files/SC_STD_NEW_ISSUE.html&#39;]\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["file_path =  dbutils.fs.ls('ENTER FILE PATH')\n","file_names = []\n","file_paths = []\n","for f in file_path:\n","  #print('file_name: ',f.name,' file_path: ', f.path[5:],' file_size (bytes): ',f.size)\n","  file_names.append(f.name)\n","  file_paths.append(f.path[5:])\n"," \n","print('file names: ',file_names)\n","print('file paths: ',file_paths)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"17bff361-364a-44c1-9449-1e75fba34639","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">/SBPI/in_files/\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">/SBPI/in_files/\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["\n","# File location and type\n","files_location = \"FILE PATH\"\n","file_type = \"csv\"\n","print(files_location)\n","\n","# CSV options\n","infer_schema = \"true\"\n","first_row_is_header = \"true\"\n","delimiter = \",\"\n","\n","df = []\n","# The applied options are for CSV files. For other file types, these will be ignored.\n","i=-1\n","for f in file_paths[:]:\n","  i=1+i\n","  df[i] = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(f)\\\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5a0dbd50-6b66-44fd-98ab-e749446d5cf7","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["%sql\n","use database sbpi"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# With this registered as a temp view, it will only be available to this particular notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n","# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n","# To do so, choose your table name and uncomment the bottom line.\n","\n","permanent_table_name = \"sbpi.CATEGORY_csv\"\n","\n","df.write.format(\"delta\").saveAsTable(permanent_table_name)\n","\n","files = []\n","for i in file_names:\n","  schema='sbpi.'\n","  files.append(schema+i)\n","\n","print(files)\n","\n","files = [elem.replace('.csv', '') for elem in files]\n","\n","i=0\n","for table_name in files:\n","  t = str(table_name)\n","  df[i].write.format(\"delta\").saveAsTable(t)\n","  i+=1\n","\n"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"Ingest  tables  from CSV- DBFS Example","notebookOrigID":3000016642810892,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
